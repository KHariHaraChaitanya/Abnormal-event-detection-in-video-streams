# Abnormal-event-detection-in-video-streams

This project presents a approach to anomaly detection in video surveillance using a spatio-temporal autoencoder. The project focuses on developing a deep learning model capable of identifying unusual activities in video streams, a critical aspect of surveillance technology. By leveraging the capabilities of Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks, the model efficiently analyzes both spatial and temporal patterns in video data. The efficacy of the proposed model is demonstrated through extensive evaluation using well-known datasets like CUHK Avenue dataset and UCSD Ped dataset. These datasets provide diverse scenarios of normal and abnormal events, essential for training and validating the model’s performance. The autoencoder’s ability to reconstruct
normal sequences and detect anomalies based on reconstruction errors showcases its potential in real-time surveillance applications. Additionally, the study explores the inference of the model on an embedded device, highlighting the practical implications of deploying advanced machine learning models in real-world surveillance systems. Overall, this project offers a efficient solution for monitoring and security purposes.